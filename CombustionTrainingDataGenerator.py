import numpy as np
import os
import json
from sklearn.preprocessing import StandardScaler
from sklearn.utils import shuffle
import pickle

class TrainingDataGenerator:
    """ä»å…¸å‹æ ·æœ¬ç”Ÿæˆè®­ç»ƒæ•°æ®é›†"""
    
    def __init__(self, sample_rate=1e5):
        self.sample_rate = sample_rate
        self.base_dir = "typical_samples"
        self.mode_names = {
            0: "mode0_stable",
            1: "mode1_intermittent", 
            2: "mode2_limit_cycle",
            3: "mode3_beat"
        }
        
        # å­˜å‚¨æ‰€æœ‰æ•°æ®
        self.X = []  # ç‰¹å¾æ•°æ®
        self.y = []  # æ ‡ç­¾
        self.scaler = StandardScaler()
        
    def sliding_window(self, data, window_size, step_size):
        """æ»‘åŠ¨çª—å£åˆ‡åˆ†æ•°æ®"""
        windows = []
        
        for i in range(0, len(data) - window_size + 1, step_size):
            window = data[i:i + window_size]
            windows.append(window)
            
        return np.array(windows)
    
    def load_and_process_samples(self, window_size=2000, step_size=200):
        """
        åŠ è½½å¹¶å¤„ç†æ‰€æœ‰æ ·æœ¬
        
        å‚æ•°:
        - window_size: çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰
        - step_size: æ­¥é•¿ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰
        """
        print(f"å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®...")
        print(f"çª—å£å¤§å°: {window_size} ç‚¹ ({window_size/self.sample_rate:.3f}s)")
        print(f"æ­¥é•¿: {step_size} ç‚¹ ({step_size/self.sample_rate:.3f}s)")
        print("-" * 50)
        
        total_windows = 0
        
        for mode, mode_name in self.mode_names.items():
            mode_dir = os.path.join(self.base_dir, mode_name)
            
            if not os.path.exists(mode_dir):
                print(f"âš ï¸  æ¨¡å¼ {mode} æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {mode_dir}")
                continue
            
            # è·å–è¯¥æ¨¡å¼ä¸‹çš„æ‰€æœ‰.npyæ–‡ä»¶
            npy_files = [f for f in os.listdir(mode_dir) if f.endswith('.npy')]
            
            mode_windows = 0
            print(f"å¤„ç†æ¨¡å¼ {mode} ({mode_name}):")
            
            for npy_file in npy_files:
                data_path = os.path.join(mode_dir, npy_file)
                
                # åŠ è½½æ•°æ®
                data = np.load(data_path)
                
                # æ£€æŸ¥æ•°æ®é•¿åº¦
                if len(data) < window_size:
                    print(f"  âš ï¸  è·³è¿‡ {npy_file}: æ•°æ®é•¿åº¦({len(data)}) < çª—å£å¤§å°({window_size})")
                    continue
                
                # æ»‘åŠ¨çª—å£åˆ‡åˆ†
                windows = self.sliding_window(data, window_size, step_size)
                
                # æ·»åŠ åˆ°æ•°æ®é›†
                self.X.extend(windows)
                self.y.extend([mode] * len(windows))
                
                mode_windows += len(windows)
                print(f"  âœ“ {npy_file}: {len(windows)} ä¸ªçª—å£")
            
            total_windows += mode_windows
            print(f"  æ¨¡å¼ {mode} æ€»è®¡: {mode_windows} ä¸ªçª—å£")
            print()
        
        print(f"æ€»è®¡ç”Ÿæˆ {total_windows} ä¸ªè®­ç»ƒæ ·æœ¬")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        self.X = np.array(self.X)
        self.y = np.array(self.y)
        
        print(f"æ•°æ®å½¢çŠ¶: X={self.X.shape}, y={self.y.shape}")
        
    def normalize_data(self):
        """æ ‡å‡†åŒ–æ•°æ®"""
        print("æ­£åœ¨æ ‡å‡†åŒ–æ•°æ®...")
        
        # å°†æ•°æ®é‡å¡‘ä¸º2Dè¿›è¡Œæ ‡å‡†åŒ–
        original_shape = self.X.shape
        X_reshaped = self.X.reshape(-1, self.X.shape[-1])
        
        # æ ‡å‡†åŒ–
        X_normalized = self.scaler.fit_transform(X_reshaped)
        
        # æ¢å¤åŸå§‹å½¢çŠ¶
        self.X = X_normalized.reshape(original_shape)
        
        print("âœ“ æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")
    
    def shuffle_data(self):
        """æ‰“ä¹±æ•°æ®"""
        print("æ­£åœ¨æ‰“ä¹±æ•°æ®...")
        self.X, self.y = shuffle(self.X, self.y, random_state=42)
        print("âœ“ æ•°æ®æ‰“ä¹±å®Œæˆ")
    
    def save_training_data(self, filename="training_data.npz"):
        """ä¿å­˜è®­ç»ƒæ•°æ®"""
        print(f"æ­£åœ¨ä¿å­˜è®­ç»ƒæ•°æ®åˆ° {filename}...")
        
        # ä¿å­˜æ•°æ®
        np.savez_compressed(filename, 
                          X=self.X, 
                          y=self.y,
                          mode_names=self.mode_names)
        
        # ä¿å­˜æ ‡å‡†åŒ–å™¨
        scaler_filename = filename.replace('.npz', '_scaler.pkl')
        with open(scaler_filename, 'wb') as f:
            pickle.dump(self.scaler, f)
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        info = {
            "total_samples": len(self.X),
            "window_size": self.X.shape[1],
            "num_classes": len(self.mode_names),
            "class_distribution": {int(mode): int(np.sum(self.y == mode)) for mode in self.mode_names.keys()},
            "data_shape": self.X.shape,
            "mode_names": self.mode_names
        }
        
        info_filename = filename.replace('.npz', '_info.json')
        with open(info_filename, 'w') as f:
            json.dump(info, f, indent=2)
        
        print(f"âœ“ è®­ç»ƒæ•°æ®å·²ä¿å­˜:")
        print(f"  - æ•°æ®æ–‡ä»¶: {filename}")
        print(f"  - æ ‡å‡†åŒ–å™¨: {scaler_filename}")
        print(f"  - ä¿¡æ¯æ–‡ä»¶: {info_filename}")
        
        return info
    
    def show_data_distribution(self):
        """æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ"""
        print("\næ•°æ®åˆ†å¸ƒ:")
        print("-" * 30)
        
        for mode, mode_name in self.mode_names.items():
            count = np.sum(self.y == mode)
            percentage = count / len(self.y) * 100
            print(f"æ¨¡å¼ {mode} ({mode_name}): {count} æ ·æœ¬ ({percentage:.1f}%)")
        
        print(f"\næ€»è®¡: {len(self.y)} æ ·æœ¬")
    
    def generate_training_data(self, window_size=2000, step_size=200, 
                             normalize=True, shuffle_data=True, 
                             save_filename="training_data.npz"):
        """
        ä¸€é”®ç”Ÿæˆè®­ç»ƒæ•°æ®
        
        å‚æ•°:
        - window_size: çª—å£å¤§å°
        - step_size: æ­¥é•¿
        - normalize: æ˜¯å¦æ ‡å‡†åŒ–
        - shuffle_data: æ˜¯å¦æ‰“ä¹±
        - save_filename: ä¿å­˜æ–‡ä»¶å
        """
        
        # 1. åŠ è½½å¹¶å¤„ç†æ ·æœ¬
        self.load_and_process_samples(window_size, step_size)
        
        if len(self.X) == 0:
            print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•è®­ç»ƒæ ·æœ¬ï¼Œè¯·æ£€æŸ¥å…¸å‹æ ·æœ¬æ•°æ®")
            return None
        
        # 2. æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
        self.show_data_distribution()
        
        # 3. æ ‡å‡†åŒ–ï¼ˆå¯é€‰ï¼‰
        if normalize:
            self.normalize_data()
        
        # 4. æ‰“ä¹±æ•°æ®ï¼ˆå¯é€‰ï¼‰
        if shuffle_data:
            self.shuffle_data()
        
        # 5. ä¿å­˜æ•°æ®
        info = self.save_training_data(save_filename)
        
        print("\n" + "="*50)
        print("ğŸ‰ è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ!")
        print("="*50)
        
        return info

# ========== ä½¿ç”¨ç¤ºä¾‹ ==========
def main():
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = TrainingDataGenerator()
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    info = generator.generate_training_data(
        window_size=20000,      # çª—å£å¤§å°ï¼š2000ä¸ªæ•°æ®ç‚¹
        step_size=2000,         # æ­¥é•¿ï¼š200ä¸ªæ•°æ®ç‚¹ (90%é‡å )
        normalize=True,        # æ ‡å‡†åŒ–æ•°æ®
        shuffle_data=True,     # æ‰“ä¹±æ•°æ®
        save_filename="training_data.npz"  # ä¿å­˜æ–‡ä»¶å
    )
    
    if info:
        print(f"\nç”Ÿæˆçš„è®­ç»ƒæ•°æ®ä¿¡æ¯:")
        print(f"- æ€»æ ·æœ¬æ•°: {info['total_samples']}")
        print(f"- çª—å£å¤§å°: {info['window_size']}")
        print(f"- ç±»åˆ«æ•°: {info['num_classes']}")
        print(f"- æ•°æ®å½¢çŠ¶: {info['data_shape']}")

# ========== æ•°æ®åŠ è½½ç¤ºä¾‹ ==========
def load_training_data_example():
    """å±•ç¤ºå¦‚ä½•åŠ è½½è®­ç»ƒæ•°æ®"""
    print("åŠ è½½è®­ç»ƒæ•°æ®ç¤ºä¾‹:")
    
    # åŠ è½½æ•°æ®
    data = np.load('training_data.npz')
    X = data['X']
    y = data['y']
    mode_names = data['mode_names'].item()
    
    print(f"Xå½¢çŠ¶: {X.shape}")
    print(f"yå½¢çŠ¶: {y.shape}")
    print(f"æ¨¡å¼åç§°: {mode_names}")
    
    # åŠ è½½æ ‡å‡†åŒ–å™¨
    with open('training_data_scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    
    print("âœ“ è®­ç»ƒæ•°æ®åŠ è½½å®Œæˆ")
    
    return X, y, mode_names, scaler

if __name__ == "__main__":
    main()
    
    # å¦‚æœéœ€è¦æµ‹è¯•åŠ è½½
    # load_training_data_example()